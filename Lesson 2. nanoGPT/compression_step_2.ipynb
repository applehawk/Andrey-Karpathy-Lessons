{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e1f1a1a1",
            "metadata": {},
            "source": [
                "# –≠—Ç–∞–ø 1: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —Å–∂–∞—Ç–∏—è\n",
                "\n",
                "–ú—ã —É–∂–µ –∑–Ω–∞–µ–º —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏. –¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤—ã—è—Å–Ω–∏–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–∞ ¬´—Ö—Ä—É–ø–∫–∞—è¬ª –∏ –≥–¥–µ –ø—Ä—è—á—É—Ç—Å—è –≥–ª–∞–≤–Ω—ã–µ –≤—Ä–∞–≥–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è."
            ]
        },
        {
            "cell_type": "code",
            "id": "e2f2a2a2",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from src.model import GPTLanguageModel, device\n",
                "\n",
                "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ —É–∂–µ –æ–±—É—á–µ–Ω–Ω—É—é)\n",
                "model = GPTLanguageModel().to(device)\n",
                "try:\n",
                "    model.load_state_dict(torch.load('model_ckpt.pt', map_location=device))\n",
                "    print(\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –∏–∑ model_ckpt.pt\")\n",
                "except:\n",
                "    print(\"‚ö†Ô∏è –ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞ (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–º–∏)\")\n",
                "\n",
                "model.eval()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3f3a3a3",
            "metadata": {},
            "source": [
                "### 1. –ê–Ω–∞–ª–∏–∑ –í—ã–±—Ä–æ—Å–æ–≤ (Outliers Analysis)\n",
                "–í—ã–±—Ä–æ—Å—ã ‚Äî —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω–æ –≤—ã–±–∏–≤–∞—é—Ç—Å—è –∏–∑ –æ–±—â–µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –û–Ω–∏ –∑–∞—Å—Ç–∞–≤–ª—è—é—Ç –∫–≤–∞–Ω—Ç–æ–≤–∞—Ç–µ–ª—å –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–∏—à–∫–æ–º —à–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω, –∏–∑-–∑–∞ —á–µ–≥–æ 99% –æ–±—ã—á–Ω—ã—Ö –≤–µ—Å–æ–≤ —Ç–µ—Ä—è—é—Ç —Ç–æ—á–Ω–æ—Å—Ç—å."
            ]
        },
        {
            "cell_type": "code",
            "id": "e4f4a4a4",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_outliers(mdl, threshold_sigma=3.0):\n",
                "    print(f\"{'Layer Name':<40} | {'Max Val':<10} | {'Outliers %':<10}\")\n",
                "    print(\"-\" * 70)\n",
                "    \n",
                "    for name, param in mdl.named_parameters():\n",
                "        if 'weight' in name and param.dim() > 1:\n",
                "            data = param.data.cpu().numpy().flatten()\n",
                "            mean = np.mean(data)\n",
                "            std = np.std(data)\n",
                "            \n",
                "            # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –≤–µ—Å–æ–≤ –≤—ã—Ö–æ–¥—è—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã N —Å–∏–≥–º\n",
                "            outliers = np.sum(np.abs(data - mean) > threshold_sigma * std)\n",
                "            outlier_pct = (outliers / len(data)) * 100\n",
                "            \n",
                "            print(f\"{name[:40]:<40} | {np.max(np.abs(data)):<10.4f} | {outlier_pct:<10.2f}%\")\n",
                "\n",
                "analyze_outliers(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f5a5a5",
            "metadata": {},
            "source": [
                "### 2. Saliency: –ö–∞–∫–∏–µ —Å–ª–æ–∏ –≤–∞–∂–Ω–µ–µ?\n",
                "–ú—ã –¥–æ–±–∞–≤–∏–º –∫ –≤–µ—Å–∞–º —à—É–º —Ä–∞–∑–Ω–æ–π –∞–º–ø–ª–∏—Ç—É–¥—ã –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —ç—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ Loss. –≠—Ç–æ –ø–æ–∫–∞–∂–µ—Ç –Ω–∞–º ¬´—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å¬ª –º–æ–¥–µ–ª–∏ –∫ –ø–æ—Ä—á–µ –¥–∞–Ω–Ω—ã—Ö."
            ]
        },
        {
            "cell_type": "code",
            "id": "e6f6a6a6",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.model import get_batch\n",
                "\n",
                "def measure_sensitivity(mdl, noise_level=0.01):\n",
                "    xb, yb = get_batch('val')\n",
                "    \n",
                "    # –ë–∞–∑–æ–≤—ã–π –ª–æ—Å—Å\n",
                "    with torch.no_grad():\n",
                "        _, base_loss = mdl(xb, yb)\n",
                "    \n",
                "    print(f\"–ë–∞–∑–æ–≤—ã–π Loss –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {base_loss.item():.4f}\\n\")\n",
                "    print(f\"{'Layer to noise':<40} | {'Delta Loss':<10} | {'Sensitivity'}\")\n",
                "    print(\"-\" * 75)\n",
                "\n",
                "    for name, param in mdl.named_parameters():\n",
                "        if 'weight' in name and param.dim() > 1:\n",
                "            orig_data = param.data.clone()\n",
                "            \n",
                "            # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º\n",
                "            noise = torch.randn_like(param.data) * noise_level\n",
                "            param.data.add_(noise)\n",
                "            \n",
                "            with torch.no_grad():\n",
                "                _, new_loss = mdl(xb, yb)\n",
                "            \n",
                "            delta = new_loss.item() - base_loss.item()\n",
                "            \n",
                "            # –û—Ü–µ–Ω–∫–∞: —á–µ–º –≤—ã—à–µ Sensitivity, —Ç–µ–º –æ–ø–∞—Å–Ω–µ–µ —Å–∂–∏–º–∞—Ç—å —ç—Ç–æ—Ç —Å–ª–æ–π\n",
                "            sensitivity = \"üî¥ HIGH\" if delta > 0.05 else (\"üü° MED\" if delta > 0.01 else \"üü¢ LOW\")\n",
                "            \n",
                "            print(f\"{name[:40]:<40} | {delta:<10.4f} | {sensitivity}\")\n",
                "            \n",
                "            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å–∞ –Ω–∞–∑–∞–¥!\n",
                "            param.data.copy_(orig_data)\n",
                "\n",
                "measure_sensitivity(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e7f7a7a7",
            "metadata": {},
            "source": [
                "### –í—ã–≤–æ–¥—ã –≠—Ç–∞–ø–∞ 1:\n",
                "1. **Outliers**: –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç –≤—ã–±—Ä–æ—Å–æ–≤ –≤—ã—Å–æ–∫, –æ–±—ã—á–Ω–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ (Min-Max) —Å–∏–ª—å–Ω–æ —É—Ä–æ–Ω–∏—Ç —Ç–æ—á–Ω–æ—Å—Ç—å. –ù–∞–º –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –º–µ—Ç–æ–¥—ã –≤—Ä–æ–¥–µ **Clamping** –∏–ª–∏ **SmoothQuant**.\n",
                "2. **Sensitivity**: –°–ª–æ–∏ —Å –ø–æ–º–µ—Ç–∫–æ–π üî¥ HIGH –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ—Å—Ç–∞–≤–∏—Ç—å –≤ FP16) –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –Ω–∏—Ö –±–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏—Ç."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.13 (nanoGPT)",
            "language": "python",
            "name": "nanogpt"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}