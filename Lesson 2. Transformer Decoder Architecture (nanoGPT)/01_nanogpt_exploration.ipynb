{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# nanoGPT: \u0413\u043b\u0443\u0431\u043e\u043a\u043e\u0435 \u043f\u043e\u0433\u0440\u0443\u0436\u0435\u043d\u0438\u0435 \u0432 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443\n",
    "\n",
    "\u0412 \u044d\u0442\u043e\u043c \u0431\u043b\u043e\u043a\u043d\u043e\u0442\u0435 \u043c\u044b \u0434\u0435\u0442\u0430\u043b\u044c\u043d\u043e \u0438\u0437\u0443\u0447\u0438\u043c \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044e nanoGPT, \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0435 \u0432\u0435\u0441\u0430 \u0438 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u0435\u0435 \u0443\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u043e \u0441\u043b\u043e\u0435\u0432."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Using device: mps\n",
      "\u0423\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u043e: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.model import GPTLanguageModel, Block, MultiHeadAttention, Head, FeedFoward\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"\u0423\u0441\u0442\u0440\u043e\u0439\u0441\u0442\u0432\u043e: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading",
   "metadata": {},
   "source": [
    "## 1. \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0432\u0435\u0441\u043e\u0432\n",
    "\n",
    "\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0438 \u0447\u0435\u043a\u043f\u043e\u0438\u043d\u0442 `model_ckpt.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_ckpt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 \u0427\u0435\u043a\u043f\u043e\u0438\u043d\u0442 nanoGPT-lab/model_ckpt.pt \u0443\u0441\u043f\u0435\u0448\u043d\u043e \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d.\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel().to(device)\n",
    "\n",
    "# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0447\u0435\u043a\u043f\u043e\u0438\u043d\u0442 \u0447\u0435\u0440\u0435\u0437 symlink nanoGPT-lab\n",
    "ckpt_path = 'nanoGPT-lab/model_ckpt.pt'\n",
    "\n",
    "if os.path.exists(ckpt_path):\n",
    "    state_dict = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(f\"\u2705 \u0427\u0435\u043a\u043f\u043e\u0438\u043d\u0442 {ckpt_path} \u0443\u0441\u043f\u0435\u0448\u043d\u043e \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d.\")\n",
    "else:\n",
    "    print(f\"\u26a0\ufe0f  \u0412\u041d\u0418\u041c\u0410\u041d\u0418\u0415: \u0424\u0430\u0439\u043b {ckpt_path} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d. \u0420\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 \u043d\u0435\u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u0435\u0441\u0430\u043c\u0438.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_hierarchy",
   "metadata": {},
   "source": [
    "## 2. \u0418\u0435\u0440\u0430\u0440\u0445\u0438\u044f \u0441\u043b\u043e\u0435\u0432 PyTorch\n",
    "\n",
    "\u0414\u0430\u0432\u0430\u0439\u0442\u0435 \u0440\u0435\u043a\u0443\u0440\u0441\u0438\u0432\u043d\u043e \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0432\u0441\u0435 \u043c\u043e\u0434\u0443\u043b\u0438 \u043c\u043e\u0434\u0435\u043b\u0438."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "print_hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 GPTLanguageModel:\n",
      "- token_embedding_table: Embedding\n",
      "- position_embedding_table: Embedding\n",
      "- blocks: Sequential\n",
      "  - 0: Block\n",
      "    - sa: MultiHeadAttention\n",
      "      - heads: ModuleList\n",
      "        - 0: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 1: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 2: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 3: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 4: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 5: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "      - proj: Linear\n",
      "      - dropout: Dropout\n",
      "    - ffwd: FeedFoward\n",
      "      - net: Sequential\n",
      "        - 0: Linear\n",
      "        - 1: ReLU\n",
      "        - 2: Linear\n",
      "        - 3: Dropout\n",
      "    - ln1: LayerNorm\n",
      "    - ln2: LayerNorm\n",
      "  - 1: Block\n",
      "    - sa: MultiHeadAttention\n",
      "      - heads: ModuleList\n",
      "        - 0: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 1: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 2: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 3: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 4: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 5: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "      - proj: Linear\n",
      "      - dropout: Dropout\n",
      "    - ffwd: FeedFoward\n",
      "      - net: Sequential\n",
      "        - 0: Linear\n",
      "        - 1: ReLU\n",
      "        - 2: Linear\n",
      "        - 3: Dropout\n",
      "    - ln1: LayerNorm\n",
      "    - ln2: LayerNorm\n",
      "  - 2: Block\n",
      "    - sa: MultiHeadAttention\n",
      "      - heads: ModuleList\n",
      "        - 0: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 1: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 2: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 3: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 4: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 5: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "      - proj: Linear\n",
      "      - dropout: Dropout\n",
      "    - ffwd: FeedFoward\n",
      "      - net: Sequential\n",
      "        - 0: Linear\n",
      "        - 1: ReLU\n",
      "        - 2: Linear\n",
      "        - 3: Dropout\n",
      "    - ln1: LayerNorm\n",
      "    - ln2: LayerNorm\n",
      "  - 3: Block\n",
      "    - sa: MultiHeadAttention\n",
      "      - heads: ModuleList\n",
      "        - 0: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 1: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 2: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 3: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 4: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 5: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "      - proj: Linear\n",
      "      - dropout: Dropout\n",
      "    - ffwd: FeedFoward\n",
      "      - net: Sequential\n",
      "        - 0: Linear\n",
      "        - 1: ReLU\n",
      "        - 2: Linear\n",
      "        - 3: Dropout\n",
      "    - ln1: LayerNorm\n",
      "    - ln2: LayerNorm\n",
      "  - 4: Block\n",
      "    - sa: MultiHeadAttention\n",
      "      - heads: ModuleList\n",
      "        - 0: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 1: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 2: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 3: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 4: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 5: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "      - proj: Linear\n",
      "      - dropout: Dropout\n",
      "    - ffwd: FeedFoward\n",
      "      - net: Sequential\n",
      "        - 0: Linear\n",
      "        - 1: ReLU\n",
      "        - 2: Linear\n",
      "        - 3: Dropout\n",
      "    - ln1: LayerNorm\n",
      "    - ln2: LayerNorm\n",
      "  - 5: Block\n",
      "    - sa: MultiHeadAttention\n",
      "      - heads: ModuleList\n",
      "        - 0: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 1: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 2: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 3: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 4: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "        - 5: Head\n",
      "          - key: Linear\n",
      "          - query: Linear\n",
      "          - value: Linear\n",
      "          - dropout: Dropout\n",
      "      - proj: Linear\n",
      "      - dropout: Dropout\n",
      "    - ffwd: FeedFoward\n",
      "      - net: Sequential\n",
      "        - 0: Linear\n",
      "        - 1: ReLU\n",
      "        - 2: Linear\n",
      "        - 3: Dropout\n",
      "    - ln1: LayerNorm\n",
      "    - ln2: LayerNorm\n",
      "- ln_f: LayerNorm\n",
      "- lm_head: Linear\n"
     ]
    }
   ],
   "source": [
    "def print_structure(module, indent=0):\n",
    "    for name, child in module.named_children():\n",
    "        print(\"  \" * indent + f\"- {name}: {type(child).__name__}\")\n",
    "        print_structure(child, indent + 1)\n",
    "\n",
    "print(\"\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 GPTLanguageModel:\")\n",
    "print_structure(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_block",
   "metadata": {},
   "source": [
    "## 3. \u0414\u0435\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u043e\u0441\u043c\u043e\u0442\u0440 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430 Transformer\n",
    "\n",
    "\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0432\u0435\u0441\u0430 \u0441\u043b\u043e\u0435\u0432 \u0432 `model.blocks[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "viz_weights",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u041e\u0441\u043c\u043e\u0442\u0440 \u0431\u043b\u043e\u043a\u0430: Block(\n",
      "  (sa): MultiHeadAttention(\n",
      "    (heads): ModuleList(\n",
      "      (0-5): 6 x Head(\n",
      "        (key): Linear(in_features=384, out_features=64, bias=False)\n",
      "        (query): Linear(in_features=384, out_features=64, bias=False)\n",
      "        (value): Linear(in_features=384, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (ffwd): FeedFoward(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "  (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "\n",
      "sa.heads.0.key.weight                    | Shape: [64, 384]            | Mean: 0.0000\n",
      "sa.heads.0.query.weight                  | Shape: [64, 384]            | Mean: 0.0001\n",
      "sa.heads.0.value.weight                  | Shape: [64, 384]            | Mean: -0.0001\n",
      "sa.heads.1.key.weight                    | Shape: [64, 384]            | Mean: -0.0001\n",
      "sa.heads.1.query.weight                  | Shape: [64, 384]            | Mean: -0.0001\n",
      "sa.heads.1.value.weight                  | Shape: [64, 384]            | Mean: 0.0002\n",
      "sa.heads.2.key.weight                    | Shape: [64, 384]            | Mean: 0.0002\n",
      "sa.heads.2.query.weight                  | Shape: [64, 384]            | Mean: -0.0001\n",
      "sa.heads.2.value.weight                  | Shape: [64, 384]            | Mean: -0.0002\n",
      "sa.heads.3.key.weight                    | Shape: [64, 384]            | Mean: -0.0001\n",
      "sa.heads.3.query.weight                  | Shape: [64, 384]            | Mean: 0.0001\n",
      "sa.heads.3.value.weight                  | Shape: [64, 384]            | Mean: -0.0000\n",
      "sa.heads.4.key.weight                    | Shape: [64, 384]            | Mean: -0.0003\n",
      "sa.heads.4.query.weight                  | Shape: [64, 384]            | Mean: 0.0002\n",
      "sa.heads.4.value.weight                  | Shape: [64, 384]            | Mean: -0.0001\n",
      "sa.heads.5.key.weight                    | Shape: [64, 384]            | Mean: -0.0000\n",
      "sa.heads.5.query.weight                  | Shape: [64, 384]            | Mean: 0.0003\n",
      "sa.heads.5.value.weight                  | Shape: [64, 384]            | Mean: 0.0000\n",
      "sa.proj.weight                           | Shape: [384, 384]           | Mean: -0.0000\n",
      "sa.proj.bias                             | Shape: [384]                | Mean: 0.0001\n",
      "ffwd.net.0.weight                        | Shape: [1536, 384]          | Mean: 0.0000\n",
      "ffwd.net.0.bias                          | Shape: [1536]               | Mean: -0.0187\n",
      "ffwd.net.2.weight                        | Shape: [384, 1536]          | Mean: -0.0000\n",
      "ffwd.net.2.bias                          | Shape: [384]                | Mean: -0.0000\n",
      "ln1.weight                               | Shape: [384]                | Mean: 0.9962\n",
      "ln1.bias                                 | Shape: [384]                | Mean: 0.0002\n",
      "ln2.weight                               | Shape: [384]                | Mean: 0.9630\n",
      "ln2.bias                                 | Shape: [384]                | Mean: 0.0001\n"
     ]
    }
   ],
   "source": [
    "first_block = model.blocks[0]\n",
    "print(f\"\u041e\u0441\u043c\u043e\u0442\u0440 \u0431\u043b\u043e\u043a\u0430: {first_block}\\n\")\n",
    "\n",
    "for name, param in first_block.named_parameters():\n",
    "    print(f\"{name:40} | Shape: {str(list(param.shape)):20} | Mean: {param.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svd_expanded_title",
   "metadata": {},
   "source": [
    "## 4. \u0420\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u043d\u044b\u0439 SVD \u0430\u043d\u0430\u043b\u0438\u0437 (Query, Key, Value \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0433\u043e\u043b\u043e\u0432)\n",
    "\n",
    "\u0422\u0435\u043f\u0435\u0440\u044c \u043c\u044b \u043f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043d\u0435 \u0442\u043e\u043b\u044c\u043a\u043e Query, \u043d\u043e \u0438 Key/Value \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0433\u043e\u043b\u043e\u0432 \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u0431\u043b\u043e\u043a\u0430. \n",
    "\u041c\u044b \u0438\u0449\u0435\u043c '\u0441\u043b\u0430\u0431\u044b\u0435' \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u2014 \u0442\u0435, \u0443 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0437\u043d\u0430\u0447\u0438\u043c\u044b\u0445 \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u0447\u0438\u0441\u0435\u043b (\u0432\u044b\u0448\u0435 10% \u043e\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c\u0430) \u043c\u0435\u043d\u044c\u0448\u0435 64 (\u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0433\u043e\u043b\u043e\u0432\u044b)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svd_intro_tool",
   "metadata": {},
   "source": [
    "### 2. \u0413\u043b\u0430\u0432\u043d\u044b\u0439 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u2014 SVD (Singular Value Decomposition)\n",
    "\n",
    "\u0414\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0438 \u0441\u0436\u0430\u0442\u0438\u044f \u043c\u0430\u0442\u0440\u0438\u0446 \u043c\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0440\u0430\u0437\u043b\u043e\u0436\u0435\u043d\u0438\u0435:\n",
    "$$W = U \\Sigma V^T$$\n",
    "\n",
    "- $\\Sigma = \\text{diag}(\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge 0)$ \u2014 \u0434\u0438\u0430\u0433\u043e\u043d\u0430\u043b\u044c\u043d\u0430\u044f \u043c\u0430\u0442\u0440\u0438\u0446\u0430 \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u0447\u0438\u0441\u0435\u043b.\n",
    "- $\\sigma_i$ \u2014 \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f, \u0443\u043f\u043e\u0440\u044f\u0434\u043e\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u043e \u043d\u0435\u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430\u043d\u0438\u044e.\n",
    "\n",
    "\ud83d\udccc **\u0427\u0442\u043e \u043e\u043d\u0438 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442?**\n",
    "\u041a\u0430\u0436\u0434\u043e\u0435 \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 $\\sigma_i$ \u0431\u0443\u043a\u0432\u0430\u043b\u044c\u043d\u043e \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442, **\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u00ab\u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438\u00bb \u0438\u043b\u0438 \u00ab\u044d\u043d\u0435\u0440\u0433\u0438\u0438\u00bb** \u043d\u0435\u0441\u0435\u0442 \u0432 \u0441\u0435\u0431\u0435 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0435\u0435 \u0435\u043c\u0443 \u043d\u0430\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 (\u0433\u043b\u0430\u0432\u043d\u0430\u044f \u043a\u043e\u043c\u043f\u043e\u043d\u0435\u043d\u0442\u0430). \u0427\u0435\u043c \u0431\u044b\u0441\u0442\u0440\u0435\u0435 \u0443\u0431\u044b\u0432\u0430\u044e\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f $\\sigma_i$, \u0442\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435 \u043c\u0430\u0442\u0440\u0438\u0446\u0430 \u00ab\u0441\u043a\u043b\u043e\u043d\u043d\u0430\u00bb \u043a \u0441\u0438\u043b\u044c\u043d\u043e\u043c\u0443 \u0441\u0436\u0430\u0442\u0438\u044e \u0431\u0435\u0437 \u043f\u043e\u0442\u0435\u0440\u0438 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svd_theory_info",
   "metadata": {},
   "source": [
    "### \u041c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043e\u0431\u043e\u0441\u043d\u043e\u0432\u0430\u043d\u0438\u0435: \u041a\u0430\u043a \u0432\u044b\u0431\u0438\u0440\u0430\u0442\u044c \u0440\u0430\u043d\u0433 $r$?\n",
    "\n",
    "SVD \u2014 \u044d\u0442\u043e \u043d\u0435 \u043f\u0440\u043e\u0441\u0442\u043e \u0441\u043f\u043e\u0441\u043e\u0431 \u0440\u0430\u0437\u043b\u043e\u0436\u0438\u0442\u044c \u043c\u0430\u0442\u0440\u0438\u0446\u0443, \u044d\u0442\u043e \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442 \u0434\u043b\u044f \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0441\u0436\u0430\u0442\u0438\u044f \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438. \u0412\u043e\u0442 \u043a\u043b\u044e\u0447\u0435\u0432\u044b\u0435 \u0441\u043f\u043e\u0441\u043e\u0431\u044b \u0432\u044b\u0431\u043e\u0440\u0430 \u0440\u0430\u043d\u0433\u0430 $r$ \u0434\u043b\u044f \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u0438 $W \\approx U_r \\Sigma_r V_r^T$:\n",
    "\n",
    "#### 1. \u041f\u043e \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044e \u044d\u043d\u0435\u0440\u0433\u0438\u0438 (\u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0439)\n",
    "\u041c\u044b \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u043c \u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0440\u0430\u043d\u0433 $r$, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u0442 \u0437\u0430\u0434\u0430\u043d\u043d\u044b\u0439 \u043f\u0440\u043e\u0446\u0435\u043d\u0442 \u00ab\u044d\u043d\u0435\u0440\u0433\u0438\u0438\u00bb (\u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u0438) \u043c\u0430\u0442\u0440\u0438\u0446\u044b:\n",
    "$$\\frac{\\sum_{i=1}^{r} \\sigma_i^2}{\\sum_{i=1}^{d} \\sigma_i^2} \\ge 1 - \\varepsilon$$\n",
    "\n",
    "**\u0422\u0438\u043f\u0438\u0447\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f:**\n",
    "- $\\varepsilon = 0.01 \\rightarrow$ \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c 99% \u044d\u043d\u0435\u0440\u0433\u0438\u0438.\n",
    "- $\\varepsilon = 0.05 \\rightarrow$ \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c 95% \u044d\u043d\u0435\u0440\u0433\u0438\u0438.\n",
    "\n",
    "\ud83d\udccc *\u0412 \u0441\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 LLM \u0447\u0430\u0441\u0442\u043e \u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0434\u043b\u044f \u043c\u0430\u0442\u0440\u0438\u0446 \u0432\u0435\u0441\u043e\u0432 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e $r = 16\\dots128$ \u043f\u0440\u0438 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u043c \u0440\u0430\u0437\u043c\u0435\u0440\u0435 4096+.*\n",
    "\n",
    "#### 2. \u0427\u0435\u0440\u0435\u0437 \u043e\u0448\u0438\u0431\u043a\u0443 \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u0438\n",
    "\u0421\u043e\u0433\u043b\u0430\u0441\u043d\u043e \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430\u043c SVD, \u043a\u0432\u0430\u0434\u0440\u0430\u0442 \u043d\u043e\u0440\u043c\u044b \u0424\u0440\u043e\u0431\u0435\u043d\u0438\u0443\u0441\u0430 \u0440\u0430\u0437\u043d\u043e\u0441\u0442\u0438 \u043c\u0435\u0436\u0434\u0443 \u043e\u0440\u0438\u0433\u0438\u043d\u0430\u043b\u043e\u043c \u0438 \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u0435\u0439 \u0440\u0430\u0432\u0435\u043d \u0441\u0443\u043c\u043c\u0435 \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043e\u0432 \u043e\u0442\u0431\u0440\u043e\u0448\u0435\u043d\u043d\u044b\u0445 \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0445 \u0447\u0438\u0441\u0435\u043b:\n",
    "$$\\|W - W_r\\|_F^2 = \\sum_{i=r+1}^{d} \\sigma_i^2$$\n",
    "\u0412\u044b \u0432\u044b\u0431\u0438\u0440\u0430\u0435\u0442\u0435 $r$, \u043f\u0440\u0438 \u043a\u043e\u0442\u043e\u0440\u043e\u043c \u043e\u0448\u0438\u0431\u043a\u0430 \u043f\u0430\u0434\u0430\u0435\u0442 \u043d\u0438\u0436\u0435 \u0434\u043e\u043f\u0443\u0441\u0442\u0438\u043c\u043e\u0433\u043e \u043f\u043e\u0440\u043e\u0433\u0430.\n",
    "\n",
    "#### 3. \u041f\u043e\u0447\u0435\u043c\u0443 \u0438\u043c\u0435\u043d\u043d\u043e SVD? (\u0422\u0435\u043e\u0440\u0435\u043c\u0430 \u042d\u043a\u043a\u0430\u0440\u0442\u0430\u2013\u042e\u043d\u0433\u0430)\n",
    "\u042d\u0442\u043e \u043a\u0440\u0438\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u0432\u0430\u0436\u043d\u044b\u0439 \u043c\u043e\u043c\u0435\u043d\u0442. \u041f\u043e\u0447\u0435\u043c\u0443 \u043c\u044b \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u0438\u0435 \u0440\u0430\u0437\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u0441\u0436\u0430\u0442\u0438\u044f? \n",
    "\n",
    "> **\u0422\u0435\u043e\u0440\u0435\u043c\u0430 \u042d\u043a\u043a\u0430\u0440\u0442\u0430\u2013\u042e\u043d\u0433\u0430:** \u0423\u0441\u0435\u0447\u0435\u043d\u043d\u043e\u0435 SVD (Truncated SVD) \u0434\u0430\u0435\u0442 **\u043d\u0430\u0438\u043b\u0443\u0447\u0448\u0443\u044e** \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u0443\u044e \u0430\u043f\u043f\u0440\u043e\u043a\u0441\u0438\u043c\u0430\u0446\u0438\u044e \u0440\u0430\u043d\u0433\u0430 $r$ \u0434\u043b\u044f \u043b\u044e\u0431\u043e\u0439 \u043c\u0430\u0442\u0440\u0438\u0446\u044b \u0432 \u0441\u043c\u044b\u0441\u043b\u0435 \u043d\u043e\u0440\u043c\u044b \u0424\u0440\u043e\u0431\u0435\u043d\u0438\u0443\u0441\u0430 \u0438 \u0441\u043f\u0435\u043a\u0442\u0440\u0430\u043b\u044c\u043d\u043e\u0439 \u043d\u043e\u0440\u043c\u044b.\n",
    "\n",
    "\ud83d\udccc *\u042d\u0442\u043e \u043d\u0435 \u044d\u043c\u043f\u0438\u0440\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043f\u0440\u0430\u0432\u0438\u043b\u043e (\u044d\u0432\u0440\u0438\u0441\u0442\u0438\u043a\u0430) \u2014 \u044d\u0442\u043e \u0441\u0442\u0440\u043e\u0433\u0430\u044f \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0433\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e SVD \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u0432 \u0437\u0430\u0434\u0430\u043d\u043d\u044b\u0439 \u043e\u0431\u044a\u0435\u043c \u043f\u0430\u043c\u044f\u0442\u0438.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "svd_expanded_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_matrix_comprehensive(W, energy_threshold=0.95, sig_threshold_pct=0.1):\n",
    "    W_cpu = W.detach().cpu()\n",
    "    U, S, V = torch.linalg.svd(W_cpu)\n",
    "    S_np = S.numpy()\n",
    "    \n",
    "    # 1. \u041f\u043e\u0440\u043e\u0433 \u043f\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044e (10% \u043e\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c\u0430)\n",
    "    max_val = S_np[0]\n",
    "    significant_val = np.sum(S_np > (max_val * sig_threshold_pct))\n",
    "    \n",
    "    # 2. \u041f\u043e\u0440\u043e\u0433 \u043f\u043e \u044d\u043d\u0435\u0440\u0433\u0438\u0438 (95% \u0441\u0443\u043c\u043c\u044b \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043e\u0432)\n",
    "    total_energy = np.sum(S_np**2)\n",
    "    cumulative_energy = np.cumsum(S_np**2) / total_energy\n",
    "    significant_energy = np.argmax(cumulative_energy >= energy_threshold) + 1\n",
    "    \n",
    "    return S_np, significant_val, significant_energy\n",
    "\n",
    "block_idx = 0\n",
    "block = model.blocks[block_idx]\n",
    "num_heads = len(block.sa.heads)\n",
    "\n",
    "print(f\"--- \u0420\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u043d\u044b\u0439 \u0430\u043d\u0430\u043b\u0438\u0437 \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u043e\u0441\u0442\u0438 (\u0411\u043b\u043e\u043a {block_idx}) ---\")\n",
    "print(f\"\u0420\u0430\u0437\u043c\u0435\u0440 \u0433\u043e\u043b\u043e\u0432\u044b: 64\")\n",
    "print(f\"{'\u041c\u0430\u0442\u0440\u0438\u0446\u0430':<15} | {'Sig (>10%)':<12} | {'Energy (95%)':<12}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "fig, axes = plt.subplots(num_heads, 3, figsize=(15, 3 * num_heads))\n",
    "\n",
    "for h in range(num_heads):\n",
    "    head = block.sa.heads[h]\n",
    "    for i, (m_name, layer) in enumerate([('Query', head.query), ('Key', head.key), ('Value', head.value)]):\n",
    "        W = layer.weight.data\n",
    "        S_np, sig_val, sig_eng = analyze_matrix_comprehensive(W)\n",
    "        \n",
    "        full_name = f\"H{h} {m_name}\"\n",
    "        print(f\"{full_name:<15} | {sig_val:<12} | {sig_eng:<12}\")\n",
    "        \n",
    "        ax = axes[h, i]\n",
    "        ax.plot(S_np, label=r'$\\sigma_i$')\n",
    "        # \u041e\u0442\u0440\u0438\u0441\u043e\u0432\u043a\u0430 \u043f\u043e\u0440\u043e\u0433\u0430 95% \u044d\u043d\u0435\u0440\u0433\u0438\u0438\n",
    "        ax.axvline(x=sig_eng, color='orange', linestyle='--', alpha=0.5, label='95% Energy')\n",
    "        ax.set_title(f\"{full_name}\\nEng95: {sig_eng}/64\")\n",
    "        ax.grid(True)\n",
    "        if h == 0 and i == 0: ax.legend()\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udccc \u0418\u043d\u0442\u0435\u0440\u043f\u0440\u0435\u0442\u0430\u0446\u0438\u044f:\")\n",
    "print(\"1. \u0415\u0441\u043b\u0438 'Sig (>10%)' = 64, \u044d\u0442\u043e \u0437\u043d\u0430\u0447\u0438\u0442, \u0447\u0442\u043e \u0441\u0438\u043d\u0433\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0447\u0438\u0441\u043b\u0430 \u0443\u0431\u044b\u0432\u0430\u044e\u0442 \u043e\u0447\u0435\u043d\u044c \u043c\u0435\u0434\u043b\u0435\u043d\u043d\u043e (\u043c\u0430\u0442\u0440\u0438\u0446\u0430 \u043f\u043b\u043e\u0442\u043d\u0430\u044f).\")\n",
    "print(\"2. \u0415\u0441\u043b\u0438 'Energy (95%)' \u0437\u0430\u043c\u0435\u0442\u043d\u043e \u043c\u0435\u043d\u044c\u0448\u0435 64, \u0442\u043e \u043c\u0430\u0442\u0440\u0438\u0446\u0430 \u0434\u043e\u043f\u0443\u0441\u043a\u0430\u0435\u0442 \u044d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u043e\u0435 \u0441\u0436\u0430\u0442\u0438\u0435.\")\n",
    "print(\"3. \u0412 \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u0438\u0445 \u043c\u043e\u0434\u0435\u043b\u044f\u0445 (\u043a\u0430\u043a nanoGPT) \u0433\u043e\u043b\u043e\u0432\u044b \u0447\u0430\u0441\u0442\u043e \u0438\u043c\u0435\u044e\u0442 \u043f\u043e\u043b\u043d\u044b\u0439 \u0440\u0430\u043d\u0433, \u0442\u0430\u043a \u043a\u0430\u043a '\u043b\u0438\u0448\u043d\u0438\u0445' \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u043c\u0435\u043d\u044c\u0448\u0435, \u0447\u0435\u043c \u0432 \u043c\u043e\u0434\u0435\u043b\u044f\u0445 \u043d\u0430 7B+.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304e7c3-6667-45f2-a228-b6159ee7ecfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}