{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "q1",
            "metadata": {},
            "source": [
                "# –≠—Ç–∞–ø 3: INT8 Quantization ‚Äî –ü–æ–ª–Ω—ã–π —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n",
                "\n",
                "–ú—ã —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–≤–µ –º–æ–¥–µ–ª–∏ –ø–æ —Ç—Ä–µ–º –∫–ª—é—á–µ–≤—ã–º –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∞–º:\n",
                "1. **Memory (–ü–∞–º—è—Ç—å)**: –§–∏–∑–∏—á–µ—Å–∫–∏–π –æ–±—ä–µ–º –∑–∞–Ω–∏–º–∞–µ–º–æ–≥–æ –º–µ—Å—Ç–∞.\n",
                "2. **Throughput (–ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å)**: –°–∫–æ–ª—å–∫–æ —Å–∏–º–≤–æ–ª–æ–≤ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –≤ —Å–µ–∫—É–Ω–¥—É.\n",
                "3. **Latency (–ó–∞–¥–µ—Ä–∂–∫–∞)**: –í—Ä–µ–º—è –¥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è —Å–∞–º–æ–≥–æ –ø–µ—Ä–≤–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ (Time to First Token)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "q_utils",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import copy\n",
                "import time\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from src.model import GPTLanguageModel, device, get_batch, estimate_loss, decode, encode\n",
                "\n",
                "def get_model_size_mb(mdl, real_int8=False):\n",
                "    if not real_int8:\n",
                "        param_size = sum(p.nelement() * p.element_size() for p in mdl.parameters())\n",
                "        buffer_size = sum(b.nelement() * b.element_size() for b in mdl.buffers())\n",
                "        return (param_size + buffer_size) / 1024**2\n",
                "    else:\n",
                "        total_bits = 0\n",
                "        for name, param in mdl.named_parameters():\n",
                "            bits = 8 if ('weight' in name and param.dim() > 1) else 32\n",
                "            total_bits += param.nelement() * bits\n",
                "        for b in mdl.buffers():\n",
                "            total_bits += b.nelement() * 32\n",
                "        return total_bits / (8 * 1024**2)\n",
                "\n",
                "@torch.no_grad()\n",
                "def measure_performance(mdl, num_tokens=50):\n",
                "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
                "    \n",
                "    # Warmup\n",
                "    _ = mdl.generate(context, max_new_tokens=5)\n",
                "    \n",
                "    # 1. Latency (TTFT)\n",
                "    start_latency = time.time()\n",
                "    _ = mdl.generate(context, max_new_tokens=1)\n",
                "    latency = (time.time() - start_latency) * 1000\n",
                "    \n",
                "    # 2. Throughput\n",
                "    start_throughput = time.time()\n",
                "    _ = mdl.generate(context, max_new_tokens=num_tokens)\n",
                "    duration = time.time() - start_throughput\n",
                "    throughput = num_tokens / duration\n",
                "    \n",
                "    return latency, throughput\n",
                "\n",
                "def quantize_tensor_int8(x):\n",
                "    x_max = x.abs().max().item()\n",
                "    if x_max == 0: return x\n",
                "    scale = x_max / 127.0\n",
                "    return torch.round(x / scale).clamp(-128, 127) * scale"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "q3",
            "metadata": {},
            "source": [
                "### 1. –ó–∞–º–µ—Ä –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ (Baseline FP32)\n",
                "–ó–¥–µ—Å—å –º—ã —Ñ–∏–∫—Å–∏—Ä—É–µ–º ¬´–∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç¬ª –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "q4",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_fp32 = GPTLanguageModel().to(device)\n",
                "try:\n",
                "    model_fp32.load_state_dict(torch.load('model_ckpt.pt', map_location=device))\n",
                "    print(\"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏.\")\n",
                "except:\n",
                "    print(\"‚ö†Ô∏è –ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –∑–∞–º–µ—Ä—ã –±—É–¥—É—Ç –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ—Å–∞—Ö.\")\n",
                "model_fp32.eval()\n",
                "\n",
                "print(\"\\n--- [STEP 1] Baseline FP32 Performance ---\")\n",
                "loss_fp32 = estimate_loss(model_fp32)['val'].item()\n",
                "size_fp32 = get_model_size_mb(model_fp32)\n",
                "lat_fp32, thr_fp32 = measure_performance(model_fp32)\n",
                "\n",
                "print(f\"üîπ Memory Usage:     {size_fp32:.2f} MB\")\n",
                "print(f\"üîπ Inference Latency: {lat_fp32:.2f} ms (Time to First Token)\")\n",
                "print(f\"üîπ Throughput Rate:   {thr_fp32:.2f} tokens/sec\")\n",
                "print(f\"üîπ Model Quality:     {loss_fp32:.4f} (Val Loss)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "q5",
            "metadata": {},
            "source": [
                "### 2. –ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –∏ –∑–∞–º–µ—Ä INT8\n",
                "–¢–µ–ø–µ—Ä—å –º—ã ¬´–ø–æ—Ä—Ç–∏–º¬ª –≤–µ—Å–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º –¥–æ 8 –±–∏—Ç –∏ —Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –∏–∑–º–µ–Ω—è—Ç—Å—è —Ç–µ –∂–µ –º–µ—Ç—Ä–∏–∫–∏."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "q6",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_int8 = copy.deepcopy(model_fp32)\n",
                "with torch.no_grad():\n",
                "    for name, param in model_int8.named_parameters():\n",
                "        if 'weight' in name and param.dim() > 1:\n",
                "            param.copy_(quantize_tensor_int8(param.data))\n",
                "\n",
                "print(\"--- [STEP 2] Quantized INT8 Performance ---\")\n",
                "loss_int8 = estimate_loss(model_int8)['val'].item()\n",
                "size_int8 = get_model_size_mb(model_int8, real_int8=True)\n",
                "lat_int8, thr_int8 = measure_performance(model_int8)\n",
                "\n",
                "print(f\"üî∏ Memory Usage:     {size_int8:.2f} MB (Estimated storage size)\")\n",
                "print(f\"üî∏ Inference Latency: {lat_int8:.2f} ms\")\n",
                "print(f\"üî∏ Throughput Rate:   {thr_int8:.2f} tokens/sec\")\n",
                "print(f\"üî∏ Model Quality:     {loss_int8:.4f} (Val Loss)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "q7",
            "metadata": {},
            "source": [
                "### 3. –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\n",
                "–°—Ä–∞–≤–Ω–∏–º –≤—ã–∏–≥—Ä—ã—à –≤ —Ä–µ—Å—É—Ä—Å–∞—Ö –ø—Ä–æ—Ç–∏–≤ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "q8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Metric</th>\n",
                            "      <th>FP32</th>\n",
                            "      <th>INT8</th>\n",
                            "      <th>Delta</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Memory (MB)</td>\n",
                            "      <td>50.156498</td>\n",
                            "      <td>19.357426</td>\n",
                            "      <td>2.6x smaller</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Throughput (tokens/s)</td>\n",
                            "      <td>39.204155</td>\n",
                            "      <td>58.561099</td>\n",
                            "      <td>+49.4% check</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Latency (ms)</td>\n",
                            "      <td>132.934332</td>\n",
                            "      <td>16.373873</td>\n",
                            "      <td>-116.56 ms</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Validation Loss</td>\n",
                            "      <td>1.512638</td>\n",
                            "      <td>1.512140</td>\n",
                            "      <td>-0.03% quality loss</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                  Metric        FP32       INT8                Delta\n",
                            "0            Memory (MB)   50.156498  19.357426         2.6x smaller\n",
                            "1  Throughput (tokens/s)   39.204155  58.561099         +49.4% check\n",
                            "2           Latency (ms)  132.934332  16.373873           -116.56 ms\n",
                            "3        Validation Loss    1.512638   1.512140  -0.03% quality loss"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "üöÄ –ò–¢–û–ì: –í—ã –æ—Å–≤–æ–±–æ–¥–∏–ª–∏ 30.80 MB –ø–∞–º—è—Ç–∏!\n",
                        "üìâ –ü–æ—Ç–µ—Ä—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ –≤—Å–µ–≥–æ -0.03%\n"
                    ]
                }
            ],
            "source": [
                "results = {\n",
                "    \"Metric\": [\"Memory (MB)\", \"Throughput (tokens/s)\", \"Latency (ms)\", \"Validation Loss\"],\n",
                "    \"FP32\": [size_fp32, thr_fp32, lat_fp32, loss_fp32],\n",
                "    \"INT8\": [size_int8, thr_int8, lat_int8, loss_int8],\n",
                "    \"Delta\": [\n",
                "        f\"{size_fp32/size_int8:.1f}x smaller\", \n",
                "        f\"{(thr_int8/thr_fp32 - 1)*100:+.1f}% check\", \n",
                "        f\"{lat_int8 - lat_fp32:+.2f} ms\", \n",
                "        f\"{(loss_int8/loss_fp32 - 1)*100:+.2f}% quality loss\"\n",
                "    ]\n",
                "}\n",
                "\n",
                "df = pd.DataFrame(results)\n",
                "display(df)\n",
                "\n",
                "print(f\"\\nüöÄ –ò–¢–û–ì: –í—ã –æ—Å–≤–æ–±–æ–¥–∏–ª–∏ {(size_fp32 - size_int8):.2f} MB –ø–∞–º—è—Ç–∏!\")\n",
                "print(f\"üìâ –ü–æ—Ç–µ—Ä—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ –≤—Å–µ–≥–æ {((loss_int8/loss_fp32 - 1)*100):.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "q10_md",
            "metadata": {},
            "source": [
                "### 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (Blind Test)\n",
                "–ù–∞–ø–∏—à–µ–º –ø—Ä–æ–º–ø—Ç –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ä–∞–∑–Ω–∏—Ü—É –≤ —Å—Ç–∏–ª–µ. \n",
                "*–ï—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ NameError, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã–ø–æ–ª–Ω–∏–ª–∏ —Å–∞–º—É—é –ø–µ—Ä–≤—É—é —è—á–µ–π–∫—É –∫–æ–¥–∞.*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "q10",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- FP32 OUTPUT ---\n",
                        "ROMEO: my man!\n",
                        "That vurs I would be married out--lend like in pheart\n",
                        "Who a fianks giving and still so, I dismins not easing\n",
                        "Because to peace and lalamost.\n",
                        "\n",
                        "ROMEO:\n",
                        "Go thou to my griend: think'st thou do, to look until it.\n",
                        "What cares herefore! who, more, more with thy life heavens\n",
                        "Bluts the worldy of what comes an opestials\n",
                        "That able tends of are so brace, do.\n",
                        "Yie who bles I am yould dispossition,\n",
                        "Thou with speeches of the friar lord by the hours,\n",
                        "In's carses to drums as full my countrary.\n",
                        "\n",
                        "KING LEWING E\n",
                        "\n",
                        "--- INT8 OUTPUT ---\n",
                        "ROMEO: ke admitate\n",
                        "he't agaid me resposes: then God stewards\n",
                        "subjiculoured at fire. Now, going stir,\n",
                        "there he beyond come bite, my foe: an heaven praid of the\n",
                        "glard of hearing blamed which was. O you had not govern grief\n",
                        "your enrascripe in the eyes, whould sthere to bound\n",
                        "singlity, spearce, I am, Joul puby of his pock,\n",
                        "and he loves with a voo, nor publish roise.\n",
                        "If I have too sigh. I doubt, how\n",
                        "be what I was the abused god.\n",
                        "\n",
                        "Second Senator:\n",
                        "Madam, by he are here both carel in him.\n",
                        "\n",
                        "First Watchman:\n",
                        "Leav\n"
                    ]
                }
            ],
            "source": [
                "from src.model import decode, encode\n",
                "\n",
                "prompt = \"ROMEO: \"\n",
                "context = torch.tensor(encode(prompt), dtype=torch.long, device=device).unsqueeze(0)\n",
                "\n",
                "print(\"--- FP32 OUTPUT ---\")\n",
                "print(decode(model_fp32.generate(context, max_new_tokens=500)[0].tolist()))\n",
                "\n",
                "print(\"\\n--- INT8 OUTPUT ---\")\n",
                "print(decode(model_int8.generate(context, max_new_tokens=500)[0].tolist()))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.13 (nanoGPT)",
            "language": "python",
            "name": "nanogpt"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
