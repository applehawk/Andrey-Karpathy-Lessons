{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "low_rank_header",
            "metadata": {},
            "source": [
                "# Урок 10: Low-Rank Factorization\n",
                "\n",
                "Сжатие через использование внутренней избыточности матриц весов. Идея: матрицу $W$ можно аппроксимировать парой матриц гораздо меньшего размера.\n",
                "\n",
                "## 1. Математическая теория\n",
                "\n",
                "### 1.1. SVD Разложение\n",
                "Любую матрицу можно представить как $U \\cdot \\Sigma \\cdot V^T$. Мы оставляем только $r$ главных компонент.\n",
                "\n",
                "### 1.2. Методы из обзора:\n",
                "*   **ASVD (Yuan et al., 2023b):** «Activation-aware SVD». Главная проблема SVD — оно минимизирует ошибку весов, а не выхода. ASVD взвешивает веса по активациям перед разложением:\n",
                "    $$W_{weighted} = W \\cdot diag(X_{rms})$$\n",
                "    Это делает сжатие гораздо менее болезненным для качества модели.\n",
                "*   **LPLR (Saha et al., 2023):** Комбинирует низкоранговое разложение с квантованием, достигая синергии.\n",
                "*   **LSAER (Sharma et al., 2024):** Исследует динамический подбор ранга (rank) для каждого слоя в отдельности.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "low_rank_impl",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "def asvd_weights_raw(W, X_rms):\n",
                "    # Взвешивание весов активациями (ASVD core logic)\n",
                "    return W * X_rms.view(1, -1)\n",
                "\n",
                "print(\"nanoGPT Track: Реализована математика активационного взвешивания матриц.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "low_rank_industrial_desc",
            "metadata": {},
            "source": [
                "## 2. Промышленная реализация: PEFT (AdaLoRA)\n",
                "Хотя SVD используется для сжатия, самый популярный «родственный» подход в индустрии — это **AdaLoRA**, который использует низкоранговое разложение для адаптации модели, динамически оптимизируя бюджет параметров."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "low_rank_industrial_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "from peft import AdaLoraConfig, get_peft_model\n",
                "try:\n",
                "    config = AdaLoraConfig(\n",
                "        r=8, target_r=4, tinit=200, tfinal=1000,\n",
                "        target_modules=[\"q_proj\", \"v_proj\"]\n",
                "    )\n",
                "    model = get_peft_model(original_llama, config)\n",
                "    print(\"Llama Track: Промышленный AdaLoRA настроен для адаптивной факторизации.\")\n",
                "except Exception as e:\n",
                "    print(f\"Ошибка: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}