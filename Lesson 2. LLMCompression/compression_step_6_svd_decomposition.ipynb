{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "s1",
            "metadata": {},
            "source": [
                "# Этап 6: SVD Decomposition (Сингулярное разложение матриц)\n",
                "\n",
                "SVD — это метод «хирургического» сжатия уже обученной модели. В отличие от LoRA, нам не нужно ничего дообучать: мы просто пересчитываем веса, чтобы они занимали меньше места."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "math_1",
            "metadata": {},
            "source": [
                "## 1. Фундаментальная математика SVD\n",
                "\n",
                "Любая матрица весов $W$ размера $M \\times N$ (где $M$ — количество выходных нейронов, $N$ — входных) может быть разложена на три матрицы:\n",
                "$$W = U \\cdot \\Sigma \\cdot V^T$$\n",
                "\n",
                "### Компоненты разложения:\n",
                "1. **$U$ ($M \\times M$)**: Левые сингулярные векторы (ортогональная матрица). Её столбцы — это «базовые выходные паттерны» нейронов.\n",
                "2. **$\\Sigma$ ($M \\times N$)**: Диагональная матрица. На диагонали стоят **сингулярные числа** (Singular Values): $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_{\\min(M,N)} \\ge 0$. \n",
                "   * *Физический смысл*: Число $\\sigma_i$ показывает, сколько «энергии» или важной информации несет $i$-е измерение в данных. \n",
                "3. **$V^T$ ($N \\times N$)**: Правые сингулярные векторы (ортогональная матрица). Её строки — это «базовые входные признаки».\n",
                "\n",
                "--- \n",
                "\n",
                "## 2. Low-Rank Approximation (Сжатие)\n",
                "\n",
                "Основная идея компрессии заключается в том, что большинство матриц в нейросетях имеют **низкий эффективный ранг**. Это значит, что первые несколько сингулярных чисел ($\\sigma$) очень большие, а остальные стремятся к нулю.\n",
                "\n",
                "Мы выбираем ранг $k \\ll \\min(M,N)$ и отбрасываем все значения после $k$-го. Получаем приближенную матрицу:\n",
                "$$W \\approx W_k = U_k \\cdot \\Sigma_k \\cdot V_k^T$$\n",
                "\n",
                "Согласно **теореме Эккарта-Янга**, $W_k$ является наилучшим возможным приближением матрицы $W$ ранга $k$ (в смысле нормы Фробениуса)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "math_2",
            "metadata": {},
            "source": [
                "## 3. Превращение в два линейных слоя\n",
                "\n",
                "Чтобы получить реальное ускорение и экономию, мы не перемножаем $U_k, \\Sigma_k$ и $V_k^T$ обратно. Вместо этого мы создаем два последовательных слоя:\n",
                "\n",
                "1. **Матрица A (входная)**: $A = \\sqrt{\\Sigma_k} \\cdot V_k^T$. Размер: $k \\times N$.\n",
                "2. **Матрица B (выходная)**: $B = U_k \\cdot \\sqrt{\\Sigma_k}$. Размер: $M \\times k$.\n",
                "\n",
                "Теперь операция $y = Wx + b$ превращается в:\n",
                "$$y = (B \\cdot (A \\cdot x)) + b$$\n",
                "\n",
                "### Экономия параметров:\n",
                "* **Было**: $M \\cdot N$\n",
                "* **Стало**: $k \\cdot N + k \\cdot M = k(N + M)$\n",
                "\n",
                "*Пример*: Слой $1024 \\times 1024$ при ранге $k=64$ сжимается в:\n",
                "$$\\frac{1024 \\cdot 1024}{64 \\cdot (1024 + 1024)} = \\frac{1048576}{131072} = 8\\text{x}$$\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "s2",
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with '.venv (Python 3.13.7)' requires the ipykernel package.\n",
                        "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: '\"/Users/vladmac/Code/ML-Colab/Andrey Karpathy Lessons/Lesson 2. nanoGPT/.venv/bin/python3\" -m pip install ipykernel -U --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "from src.model import GPTLanguageModel, device, estimate_loss, decode, encode\n",
                "import copy\n",
                "\n",
                "# 1. Загружаем оригинал\n",
                "model = GPTLanguageModel().to(device)\n",
                "model.load_state_dict(torch.load('model_ckpt.pt', map_location=device))\n",
                "model.eval()\n",
                "\n",
                "def get_val_loss(mdl):\n",
                "    with torch.no_grad():\n",
                "        return estimate_loss(mdl)['val'].item()\n",
                "\n",
                "baseline_loss = get_val_loss(model)\n",
                "print(f\"Baseline Loss (FP32): {baseline_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "energy_analysis_md",
            "metadata": {},
            "source": [
                "## 4. Спектральный анализ сингулярных чисел\n",
                "Давайте визуализируем, сколько информации мы теряем при выборе разного ранга."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "energy_analysis_code",
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mRunning cells with '.venv (Python 3.13.7)' requires the ipykernel package.\n",
                        "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
                        "\u001b[1;31mCommand: '\"/Users/vladmac/Code/ML-Colab/Andrey Karpathy Lessons/Lesson 2. nanoGPT/.venv/bin/python3\" -m pip install ipykernel -U --force-reinstall'"
                    ]
                }
            ],
            "source": [
                "# Возьмем первый MLP слой первого блока\n",
                "W = model.blocks[0].ffwd.net[0].weight.data.cpu()\n",
                "U, S, Vh = torch.linalg.svd(W, full_matrices=False)\n",
                "\n",
                "# Считаем кумулятивное сохранение энергии (энергия = квадрат сингулярного числа)\n",
                "s_squared = S**2\n",
                "energy_cumulative = torch.cumsum(s_squared, dim=0) / torch.sum(s_squared)\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(energy_cumulative.numpy(), label='Cumulative Energy')\n",
                "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Energy Threshold')\n",
                "plt.axhline(y=0.95, color='g', linestyle='--', label='95% Energy Threshold')\n",
                "plt.title(\"SVD Energy Spectrum (MLP Layer 0)\")\n",
                "plt.xlabel(\"Singular Value Index (Rank)\")\n",
                "plt.ylabel(\"Fraction of Total Energy\")\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()\n",
                "\n",
                "k_95 = (energy_cumulative < 0.95).sum().item()\n",
                "print(f\"Ранг оригинальной матрицы: {len(S)}\")\n",
                "print(f\"Ранг для сохранения 95% энергии: {k_95} (Сжатие ~{len(S)/k_95:.1f}x)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "s3",
            "metadata": {},
            "source": [
                "## 5. Реализация SVD сжатия\n",
                "Теперь мы применим выбранный ранк ко всей модели."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "s4",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SVDLinear(nn.Module):\n",
                "    def __init__(self, original_linear, rank):\n",
                "        super().__init__()\n",
                "        W = original_linear.weight.data.cpu() # Уходим на CPU для SVD (предотвращаем Warning)\n",
                "        bias = original_linear.bias\n",
                "        \n",
                "        U, S, Vh = torch.linalg.svd(W, full_matrices=False)\n",
                "        \n",
                "        U_reduced = U[:, :rank]\n",
                "        S_reduced = S[:rank]\n",
                "        Vh_reduced = Vh[:rank, :]\n",
                "        \n",
                "        S_sqrt = torch.diag(torch.sqrt(S_reduced))\n",
                "        \n",
                "        # Возвращаем параметры на целевое устройство\n",
                "        self.A = nn.Linear(original_linear.in_features, rank, bias=False).to(device)\n",
                "        self.B = nn.Linear(rank, original_linear.out_features, bias=(bias is not None)).to(device)\n",
                "        \n",
                "        self.A.weight.data = (S_sqrt @ Vh_reduced).to(device)\n",
                "        self.B.weight.data = (U_reduced @ S_sqrt).to(device)\n",
                "        if bias is not None:\n",
                "            self.B.bias.data = bias.data.to(device)\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.B(self.A(x))\n",
                "\n",
                "def apply_svd_compression(model, rank=64):\n",
                "    for block in model.blocks:\n",
                "        block.ffwd.net[0] = SVDLinear(block.ffwd.net[0], rank=rank)\n",
                "        block.ffwd.net[2] = SVDLinear(block.ffwd.net[2], rank=rank)\n",
                "    return model\n",
                "\n",
                "model_svd = copy.deepcopy(model)\n",
                "model_svd = apply_svd_compression(model_svd, rank=64)\n",
                "\n",
                "new_loss = get_val_loss(model_svd)\n",
                "print(f\"\\nLoss после SVD (rank=64): {new_loss:.4f}\")\n",
                "print(f\"Деградация Loss: {new_loss - baseline_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "s5",
            "metadata": {},
            "source": [
                "### 6. Анализ экономии и финальный тест"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "s6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def count_params(mdl):\n",
                "    return sum(p.numel() for p in mdl.parameters())\n",
                "\n",
                "p_orig = count_params(model)\n",
                "p_svd = count_params(model_svd)\n",
                "\n",
                "print(f\"Параметры (Original): {p_orig:,}\")\n",
                "print(f\"Параметры (SVD):      {p_svd:,}\")\n",
                "print(f\"Коэффициент сжатия:   {p_orig/p_svd:.2f}x\")\n",
                "\n",
                "print(\"\\n--- [SVD Generated Output] ---\")\n",
                "context = torch.tensor(encode(\"ROMEO: \"), dtype=torch.long, device=device).unsqueeze(0)\n",
                "print(decode(model_svd.generate(context, max_new_tokens=150)[0].tolist()))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.13 (nanoGPT)",
            "language": "python",
            "name": "nanogpt"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
