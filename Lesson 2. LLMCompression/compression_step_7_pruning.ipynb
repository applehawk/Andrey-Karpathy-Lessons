{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "p1",
            "metadata": {},
            "source": [
                "# Этап 7: Pruning (Прунинг — прореживание нейросети)\n",
                "\n",
                "Если SVD сжимает матрицы, изменяя их структуру, то **Прунинг** просто «выключает» лишние связи. \n",
                "\n",
                "### Основная идея:\n",
                "Многие веса в обученной модели близки к нулю и почти не влияют на результат. Если мы их обнулим, мы получим **разреженную (sparse)** матрицу. \n",
                "\n",
                "**Magnitude-based Pruning** работает по принципу:\n",
                "1. Выбираем порог или процент весов (например, 30%).\n",
                "2. Находим веса с наименьшим абсолютным значением $|w|$.\n",
                "3. Приравниваем их к нулю.\n",
                "\n",
                "Итоговый вес: \n",
                "$$w_{pruned} = \n",
                "\\begin{cases} \n",
                "w, & \\text{if } |w| > \\text{threshold} \\\\\n",
                "0, & \\text{otherwise}\n",
                "\\end{cases}$$"
            ]
        },
        {
            "cell_type": "code",
            "id": "p2",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.utils.prune as prune\n",
                "from src.model import GPTLanguageModel, device, estimate_loss, decode, encode\n",
                "import copy\n",
                "\n",
                "# 1. Загружаем оригинал\n",
                "model = GPTLanguageModel().to(device)\n",
                "model.load_state_dict(torch.load('model_ckpt.pt', map_location=device))\n",
                "model.eval()\n",
                "\n",
                "def get_val_loss(mdl):\n",
                "    with torch.no_grad():\n",
                "        return estimate_loss(mdl)['val'].item()\n",
                "\n",
                "baseline_loss = get_val_loss(model)\n",
                "print(f\"Baseline Loss (FP32): {baseline_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "p3",
            "metadata": {},
            "source": [
                "## 2. Глобальный прунинг\n",
                "Мы применим «глобальный» прунинг к модели. Это значит, что мы будем удалять 30% самых слабых связей во всей сети сразу, позволяя алгоритму самому решить, в каких слоях веса важнее."
            ]
        },
        {
            "cell_type": "code",
            "id": "p4",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_pruned = copy.deepcopy(model)\n",
                "\n",
                "# Список слоев, которые мы хотим проредить (обычно это линейные слои)\n",
                "parameters_to_prune = []\n",
                "for name, module in model_pruned.named_modules():\n",
                "    if isinstance(module, nn.Linear):\n",
                "        parameters_to_prune.append((module, 'weight'))\n",
                "\n",
                "# Применяем глобальный прунинг (удаляем 40% весов)\n",
                "prune.global_unstructured(\n",
                "    parameters_to_prune,\n",
                "    pruning_method=prune.L1Unstructured,\n",
                "    amount=0.4, # 40% связей будет обнулено\n British English)\n",
                ")\n",
                "\n",
                "print(\"✅ 40% весов во всех линейных слоях обнулены!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "p5",
            "metadata": {},
            "source": [
                "## 3. Анализ разреженности (Sparsity)\n",
                "Проверим, сколько реально нулей появилось в матрицах."
            ]
        },
        {
            "cell_type": "code",
            "id": "p6",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def check_sparsity(mdl):\n",
                "    total_zeros = 0\n",
                "    total_elements = 0\n",
                "    for name, buffer in mdl.named_buffers():\n",
                "        if 'weight_mask' in name:\n",
                "            total_zeros += torch.sum(buffer == 0).item()\n",
                "            total_elements += buffer.nelement()\n",
                "    \n",
                "    print(f\"Общая разреженность модели: {100. * total_zeros / total_elements:.2f}%\")\n",
                "\n",
                "check_sparsity(model_pruned)\n",
                "\n",
                "pruned_loss = get_val_loss(model_pruned)\n",
                "print(f\"Loss после прунинга (40%): {pruned_loss:.4f}\")\n",
                "print(f\"Деградация: {pruned_loss - baseline_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "p7",
            "metadata": {},
            "source": [
                "## 4. Почему прунинг не уменьшает файл автоматически?\n",
                "Важный момент: PyTorch просто заменяет веса на нули, но не удаляет их физически. Чтобы модель стала занимать меньше места на диске, её нужно сохранять в специальном разреженном формате или запаковать (например, через `.zip`).\n",
                "\n",
                "### Проверим эффект на генерации текста"
            ]
        },
        {
            "cell_type": "code",
            "id": "p8",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- [Pruned Model Output (40% Sparse)] ---\")\n",
                "context = torch.tensor(encode(\"ROMEO: \"), dtype=torch.long, device=device).unsqueeze(0)\n",
                "print(decode(model_pruned.generate(context, max_new_tokens=150)[0].tolist()))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "p9",
            "metadata": {},
            "source": [
                "## 5. Итеративный прунинг и Fine-tuning\n",
                "В реальности после прунинга всегда делают **Fine-tuning**, чтобы оставшиеся веса «подхватили» функции удаленных. \n",
                "\n",
                "**Ваш челлендж**: Попробуйте запустить дообучение модели из Step 5, но на прореженной модели. Вы удивитесь, насколько быстро она восстановит качество даже с 50% удаленных весов!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.13 (LLMCompression)",
            "language": "python",
            "name": "LLMCompression"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}