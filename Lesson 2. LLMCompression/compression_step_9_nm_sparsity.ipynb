{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "sparse1",
            "metadata": {},
            "source": [
                "# Этап 9: N:M Sparsity — Аппаратное ускорение разреженности\n",
                "\n",
                "В отличие от случайного прунинга (Step 7), который сложно ускорить на обычном GPU, **N:M Sparsity** (например, 2:4) поддерживается аппаратно в ядрах Tensor Core (архитектура Ampere и новее).\n",
                "\n",
                "### Идея метода:\n",
                "В каждых 4 последовательных весах мы оставляем ровно 2 ненулевых. \n",
                "*   **Результат**: Мы гарантированно экономим 50% весов.\n",
                "*   **Профит**: GPU может умножать такие матрицы почти в 2 раза быстрее."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "sparse2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import copy\n",
                "from src.model import GPTLanguageModel, device, estimate_loss\n",
                "\n",
                "model = GPTLanguageModel().to(device)\n",
                "model.load_state_dict(torch.load('model_ckpt.pt', map_location=device))\n",
                "model.eval()\n",
                "\n",
                "def apply_2_4_sparsity(layer):\n",
                "    w = layer.weight.data\n",
                "    B, C = w.shape\n",
                "    \n",
                "    # Разбиваем веса на группы по 4\n",
                "    # Для простоты примера предположим, что C кратно 4\n",
                "    w_reshaped = w.view(B, -1, 4)\n",
                "    \n",
                "    # Находим индексы 2-х самых маленьких по модулю весов в каждой группе\n",
                "    _, indices = torch.topk(w_reshaped.abs(), k=2, dim=-1, largest=False)\n",
                "    \n",
                "    # Зануляем их\n",
                "    mask = torch.ones_like(w_reshaped)\n",
                "    mask.scatter_(dim=-1, index=indices, value=0)\n",
                "    \n",
                "    layer.weight.data = (w_reshaped * mask).view(B, C)\n",
                "    return mask\n",
                "\n",
                "# Применим к проекции первого блока\n",
                "target_layer = model.blocks[0].sa.proj\n",
                "apply_2_4_sparsity(target_layer)\n",
                "\n",
                "def check_layer_sparsity(layer):\n",
                "    total = layer.weight.numel()\n",
                "    zeros = (layer.weight == 0).sum().item()\n",
                "    print(f\"Разреженность слоя: {100 * zeros / total:.1f}%\")\n",
                "\n",
                "check_layer_sparsity(target_layer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "sparse3",
            "metadata": {},
            "source": [
                "## 2. SparseGPT: Умный выбор весов для зануления\n",
                "\n",
                "Метод **SparseGPT** (упомянутый в обзоре) использует информацию о градиентах и обратной матрице Гессиана, чтобы занулять веса, которые меньше всего влияют на Loss, соблюдая паттерн 2:4."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}